{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "!pip install tabulate"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from tabulate import tabulate"
   ],
   "id": "8c24a5e2ad158633"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Dataset paths\n",
    "Q_A_PATH = \"dataset_Q_A_small.parquet\"\n",
    "TESTI_PATH = 'dataset_CONTESTI_small.parquet'\n",
    "\n",
    "# Load the datasets\n",
    "Q_A_DataSet = pd.read_parquet(Q_A_PATH)  # Load the Q&A dataset from a Parquet file\n",
    "TESTI_DataSet = pd.read_parquet(TESTI_PATH)  # Load the passages dataset from a Parquet file\n",
    "\n",
    "# Create a dictionary for quick access to passages, with 'id' as the key and 'passage' as the value\n",
    "Testi_dizionario = {row[\"id\"]: row[\"passage\"] for _, row in TESTI_DataSet.iterrows()}\n"
   ],
   "id": "ed348a927700b49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_context_to_qa_full(qa_dataset, passage_dict):\n",
    "    \"\"\"\n",
    "    For each row in the Q&A dataset, this function combines the question with all the relevant passages,\n",
    "    formatting them in the following way:\n",
    "\n",
    "    \"Question: <question> end_question Context: <passage1> ; <passage2> ; ... end_contexts\"\n",
    "    \"\"\"\n",
    "\n",
    "    def get_context(row):\n",
    "        # Handle the \"relevant_passage_ids\" column, converting it into a list if necessary\n",
    "        passage_ids = row[\"relevant_passage_ids\"]\n",
    "        if isinstance(passage_ids, str):\n",
    "            passage_ids = ast.literal_eval(passage_ids)  # Convert string to list\n",
    "\n",
    "        # Retrieve all passages corresponding to the IDs\n",
    "        passages = [passage_dict.get(pid, \"\") for pid in passage_ids]\n",
    "        # Create a string by concatenating the passages, separated by '; '\n",
    "        context_str = \" ; \".join(passages)\n",
    "\n",
    "        # Format the final string according to the requested template\n",
    "        return f\"Question: {row['question']} \\nContext: {context_str}\"\n",
    "\n",
    "    # Apply the get_context function to each row to create the new \"input_text\" column\n",
    "    qa_dataset[\"input_text\"] = qa_dataset.apply(get_context, axis=1)\n",
    "    return qa_dataset\n",
    "\n",
    "\n",
    "# Apply the function to generate the new dataset with the formatted \"input_text\" column\n",
    "Q_A_DataSet = add_context_to_qa_full(Q_A_DataSet, Testi_dizionario)\n"
   ],
   "id": "c2ba996550d64d54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a final dataset with only the \"input_text\" (question + context) and \"answer\" columns:\n",
    "final_dataset = Q_A_DataSet[[\"input_text\", \"answer\"]]\n",
    "print(tabulate(final_dataset.head(3), headers='keys', tablefmt='psql', showindex=False))\n",
    "\n",
    "# To save the new dataset in Parquet format:\n",
    "final_dataset.to_parquet(\"DB_QC_A_da_utilizzare.parquet\", index=False)\n"
   ],
   "id": "3cd65dad686c9ab2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
