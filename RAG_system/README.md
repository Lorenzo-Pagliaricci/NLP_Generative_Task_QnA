# ğŸ§  Retrieval-Augmented Generation (RAG) per Question Answering Biomedico

Questo modulo implementa un sistema **Retrieval-Augmented Generation (RAG)** progettato per incrementare l'accuratezza e la specificitÃ  delle risposte in un contesto **biomedico**, combinando il recupero semantico di informazioni con modelli generativi fine-tunati.

## âš™ï¸ Architettura del Sistema

Il sistema RAG Ã¨ suddiviso in due componenti principali:

### 1. Retrieval (Recupero)

- Estrae dinamicamente i **chunk di testo piÃ¹ rilevanti** rispetto alla domanda.
- Utilizza un indice **FAISS** costruito su embedding semantici pre-addestrati:
  - ğŸ”— Modello usato: [`BAAI/bge-base-en-v1.5`](https://huggingface.co/BAAI/bge-base-en-v1.5)
- La ricerca Ã¨ basata su **similaritÃ  coseno** tra embedding.

### 2. Generazione

- Produce risposte condizionate solo sul **contesto recuperato**.
- Utilizza modelli generativi come **BART** o **Gemma**, ottimizzati tramite **LoRA (Low-Rank Adaptation)**.
- Funziona completamente in locale su CPU/GPU MPS o CUDA.

---

## ğŸ“ Struttura dei File

### `vector_store_impl.py` â€“ Creazione dellâ€™indice FAISS

Trasforma il corpus testuale in un indice vettoriale interrogabile.

#### Flusso operativo:
- Caricamento del dataset `enelpol/rag-mini-bioasq` da Hugging Face.
- Conversione dei passaggi in oggetti `Document` con metadati.
- Suddivisione dei testi in chunk (200 caratteri, overlap 20).
- Generazione embedding con `BAAI/bge-base-en-v1.5`.
- Creazione dellâ€™indice FAISS e salvataggio locale:
  
```python
  vector_store = FAISS.from_documents(chunked_documents, embeddings)
  vector_store.save_local("faiss_index_bioasq")
```


## ğŸ” `rag_impl.py` â€“ Retrieval + Generazione

Script principale che orchestra il flusso RAG:

### ğŸ”„ Flusso operativo

1. **Caricamento embedding model** e **indice FAISS**.
2. **Embedding della query** + ricerca dei top-`k` chunk piÃ¹ simili.
3. **Composizione del prompt** con i chunk recuperati.
4. **Generazione della risposta** con modello generativo fine-tunato.

```python
retrieve = vector_store.similarity_search_with_score_by_vector(
    embedding=embeddings.embed_query(query), k=15
)
output = text_generator(prompt_text, max_length=1000)
```

# ğŸ§  Retrieval-Augmented Generation (RAG) â€“ Sistema Biomedico

Sistema che unisce **retrieval semantico** e **generazione condizionata** per rispondere a domande in ambito biomedico con maggiore accuratezza e specificitÃ .

---

## ğŸ§ª Fine-tuning del Modello Generativo

Effettuato con [ğŸ¤— Transformers](https://huggingface.co/transformers) e tecnica PEFT (LoRA), per ridurre il numero di parametri aggiornati.

### ğŸ”§ Hyperparametri principali

- `learning_rate = 1e-5`
- `train_batch_size = 5`
- `eval_batch_size = 1`
- `gradient_accumulation_steps = 2`
- `num_train_epochs = 10`
- `eval_steps = 50`
- `load_best_model_at_end = True`

### ğŸ”© Configurazione LoRA

- **Moduli target:** `q`, `k`, `v`, `o`
- `lora_alpha = 40`
- `r = 2`
- `lora_dropout = 0.5`

---

## ğŸ“ˆ Valutazione delle Prestazioni

### ğŸ“Œ Valutazione della Generazione (QA)

| Metrica   | Caratteristiche                                                                 |
|-----------|----------------------------------------------------------------------------------|
| ROUGE-L   | Sequenza comune piÃ¹ lunga (coerenza strutturale e contenutistica)              |
| METEOR    | Riconosce sinonimi/parafrasi; valuta anche la struttura grammaticale           |
| BLEU      | Precisione sugli n-grammi (meno adatta per QA con risposte parafrasate)         |

### ğŸ“Œ Valutazione del Retrieval

- **Recall@k**: verifica la presenza dei passaggi rilevanti nei top-`k` risultati.
- Misura la qualitÃ  dellâ€™indice FAISS e degli embedding semantici.

---

## ğŸ§© Integrazione e ModularitÃ 

Sistema suddiviso in moduli indipendenti:

| Script               | Funzione                                                              |
|----------------------|-----------------------------------------------------------------------|
| `vector_store_impl.py` | Costruisce lâ€™indice FAISS a partire dal corpus testuale              |
| `rag_impl.py`        | Interroga lâ€™indice e genera la risposta                               |
| `metrics_utils.py`   | Calcola ROUGE, BLEU, METEOR per la valutazione automatica             |

---

## âœ… Requisiti e Setup

Assicurati di avere installato i seguenti pacchetti:

```bash
pip install transformers datasets peft faiss-cpu accelerate evaluate langchain
```

## ğŸ›  Esecuzione

### Costruzione dellâ€™indice (solo al primo utilizzo)

```bash
python vector_store_impl.py
```

### ğŸ” Generazione della risposta per una query

Esegui il comando seguente per generare una risposta condizionata al contesto recuperato:

```bash
python rag_impl.py --query "What is the treatment for melanoma?"
```

â— Considerazioni Finali  
Il sistema migliora la precisione e la specificitÃ  delle risposte nel dominio biomedico.

Ãˆ stato ottimizzato per Apple Silicon (MPS), ma Ã¨ compatibile anche con GPU CUDA.

Tutti gli script sono modulari, documentati e facilmente riutilizzabili per esperimenti e adattamenti futuri.
