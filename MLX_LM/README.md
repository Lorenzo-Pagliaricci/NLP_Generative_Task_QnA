# ğŸ“ MLX

Questa cartella contiene tutto il necessario per sperimentare lâ€™uso della libreria **MLX-LM**, sviluppata per lâ€™esecuzione efficiente di modelli linguistici di grandi dimensioni (LLM) su dispositivi **Apple Silicon**. Ãˆ stata una delle prime soluzioni adottate nel nostro progetto per il fine-tuning e la generazione di risposte da modelli LLM ottimizzati.

---

## ğŸ¯ Obiettivo della cartella

La cartella `MLX` nasce per:

- Testare il fine-tuning di modelli con tecnica **LoRA**, a basso consumo di memoria
- Effettuare **inferenza** e generazione di risposte su prompt personalizzati
- Sfruttare lâ€™hardware Apple per eseguire LLM localmente in modo leggero ed efficiente
- Valutare la qualitÃ  delle risposte generate da modelli personalizzati

---

## ğŸ“¦ Contenuto della cartella

Allâ€™interno troverai:

- ğŸ“œ **Script `.sh`** per gestire fine-tuning, fusione e inferenza:
  - `fine_tune.sh`: fine-tuning del modello con LoRA
  - `fuse.sh`: fusione degli adapter LoRA nel modello base
  - `generate.sh`: generazione di risposte su prompt di input
  - `chat.sh`, `evaluate.sh`: script non piÃ¹ usati o non funzionanti
- ğŸ“„ **Notebook di supporto** (facoltativo)
- ğŸ“ Modelli scaricabili da Hugging Face
- âš™ï¸ Configurazioni e percorsi dei modelli base e adattati

---

## ğŸ§° Requisiti

Per eseguire i file di questa cartella:

1. Assicurati di aver installato tutte le dipendenze:

```bash
pip install -r requirements.txt
```

2. Scarica il modello da Hugging Face nel formato compatibile con MLX:

```bash
huggingface-cli download mlx-community/gemma-3-1b-it-4bit \
  --local-dir ./proveIgnazio/models/base/gemma-3-1b-it-4bit
```

3. Esegui gli script .sh direttamente da terminale:

```bash
./fine_tune.sh
./fuse.sh
./generate.sh
```

## ğŸš€ PerchÃ© MLX-LM?

MLX-LM Ã¨ una libreria progettata per girare in modo ottimale su dispositivi Apple (come MacBook con chip M1/M2/M3), ed Ã¨ utile quando si vuole:

- Eseguire modelli Hugging Face senza usare GPU dedicate  
- Ridurre lâ€™uso di memoria tramite **quantizzazione**  
- Fare **fine-tuning locale** su modelli leggeri  
- Generare risposte in modalitÃ  **offline**

### âœ… Vantaggi principali

- CompatibilitÃ  diretta con **Hugging Face**
- Supporto per **LoRA** e tecniche *parameter-efficient*
- Sfrutta appieno la **CPU e GPU Apple Silicon**
- Ideale per **sperimentazioni veloci** e **prototipazione**

---

## âš ï¸ Limiti riscontrati

Nonostante il potenziale, durante il progetto abbiamo riscontrato diverse limitazioni nellâ€™uso di MLX-LM:

- La documentazione Ã¨ ancora **incompleta**
- Mancano strumenti avanzati per modelli **personalizzati o grandi**
- La **community** Ã¨ piccola, quindi difficile trovare supporto
- Prestazioni **limitate** con modelli piÃ¹ complessi
- Integrazione complicata con tecniche piÃ¹ avanzate (es. **LoRA estese**, **training distribuito**)

---

## ğŸ”„ PerchÃ© Ã¨ stato abbandonato

Abbiamo scelto di non proseguire con MLX-LM come soluzione principale perchÃ©:

- La libreria Ã¨ ancora **immatura**
- Non garantisce **scalabilitÃ ** e **flessibilitÃ ** necessarie
- Altri framework (come **Transformers + PEFT**) offrono:
  - Supporto migliore  
  - Strumenti piÃ¹ maturi  
  - Community attiva

> ğŸ” **Nota:** Nonostante ciÃ², MLX-LM Ã¨ stata utile come fase esplorativa e resta una buona opzione per test **rapidi** su hardware Apple.

---

[â¬†ï¸ Torna al README principale](../README.md)
